{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jieba\n",
    "!pip install snownlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 對愛食記評論和食記內容進行文本分析(詞頻) ####     =>  由於資料意義不大,故僅提供參考\n",
    "import pandas as pd\n",
    "import json \n",
    "import time\n",
    "import jieba\n",
    "\n",
    "### 編寫詞頻分析函式\n",
    "def Jieba_Analysis(company,restaurant):\n",
    "    ## 將CSV內的分店留言內容與食記內容存成一整個字串\n",
    "    try:    # 開到沒資料的csv會報錯\n",
    "        df = pd.read_csv(f'C:/Users/user/Desktop/ifoodie/{company}/{restaurant}.csv')    # 路徑請視自身環境更動\n",
    "        for row in range(df.shape[0]):\n",
    "            # 列出每一列的評論內容\n",
    "            review_content = str(df.iloc[row]['文章內容'])\n",
    "\n",
    "            # 整合每一列的食記內容\n",
    "            article_content = \"\"\n",
    "            content_segment = df.iloc[row]['食記資訊'].split(\"'內容':\")\n",
    "            time_segment = df.iloc[row]['食記資訊'].split(\"'發布時間': '\")\n",
    "            for L in range(len(content_segment)-1):\n",
    "                content_row = content_segment[L+1].split(\"}, {'文章\")[0]\n",
    "                article_time = time_segment[L+1].split(\"', '內容'\")[0].strip()\n",
    "                article_timestamp = int(time.mktime(time.strptime(article_time,\"%Y/%m/%d\")))\n",
    "                Stopby_timestamp = int(time.mktime(time.strptime(\"2021/4/1\",\"%Y/%m/%d\")))\n",
    "\n",
    "                # 只對一年內的文章進行分析\n",
    "                if article_timestamp > Stopby_timestamp :\n",
    "                    article_content += content_row\n",
    "\n",
    "            # 將兩者合併成一個字串\n",
    "            all_article_string = review_content + article_content\n",
    "\n",
    "            ## 進行詞頻分析\n",
    "            word_count = {}\n",
    "            s_list = jieba.cut(all_article_string)\n",
    "            for i in s_list:\n",
    "                if i in word_count:\n",
    "                    word_count[i] += 1\n",
    "                else:\n",
    "                    word_count[i] = 1\n",
    "\n",
    "            sorted_word_count = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n",
    "            print(sorted_word_count)\n",
    "\n",
    "    except:\n",
    "        print (\"No article available!\")\n",
    "\n",
    "\n",
    "### 執行看看\n",
    "Jieba_Analysis(\"王品集團\",\"夏慕尼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 對愛食記評論和食記內容進行文本分析(情感) ####\n",
    "import pandas as pd\n",
    "import json \n",
    "import time\n",
    "from snownlp import SnowNLP\n",
    "from snownlp import sentiment\n",
    "\n",
    "### 編寫文本分析函式\n",
    "def Emotion_Analysis(company,restaurant):\n",
    "    ## 將CSV內的分店留言內容與食記內容存成一整個字串\n",
    "    try:    # 開到沒資料的csv會報錯\n",
    "        df = pd.read_csv(f'C:/Users/user/Desktop/ifoodie/{company}/{restaurant}.csv')   # 路徑請視自身環境更動\n",
    "        df2 = df.copy()\n",
    "        good_count_list= []\n",
    "        avg_score_list = []\n",
    "        bad_count_list= []\n",
    "\n",
    "        for row in range(df.shape[0]):\n",
    "            # 列出每一列的評論內容\n",
    "            review_content = str(df.iloc[row]['文章內容'])\n",
    "\n",
    "            # 整合每一列的食記內容\n",
    "            article_content = \"\"\n",
    "            content_segment = df.iloc[row]['食記資訊'].split(\"'內容':\")\n",
    "            time_segment = df.iloc[row]['食記資訊'].split(\"'發布時間': '\")\n",
    "            for L in range(len(content_segment)-1):\n",
    "                content_row = content_segment[L+1].split(\"}, {'文章\")[0]\n",
    "                article_time = time_segment[L+1].split(\"', '內容'\")[0].strip()\n",
    "                article_timestamp = int(time.mktime(time.strptime(article_time,\"%Y/%m/%d\")))\n",
    "                Stopby_timestamp = int(time.mktime(time.strptime(\"2021/4/1\",\"%Y/%m/%d\")))\n",
    "\n",
    "                # 只對一年內的文章進行分析\n",
    "                if article_timestamp > Stopby_timestamp :\n",
    "                    article_content += content_row\n",
    "\n",
    "            # 將兩者合併成一個字串\n",
    "            all_article_string = review_content + article_content\n",
    "\n",
    "            ## 進行情感分析\n",
    "            total_score = 0\n",
    "            good_count = 0\n",
    "            bad_count = 0\n",
    "\n",
    "            s = SnowNLP(all_article_string) \n",
    "            for sentence in s.sentences : \n",
    "                if \"nan\" in sentence:\n",
    "                    pass\n",
    "                else:\n",
    "                    sentiments_score = SnowNLP(sentence).sentiments \n",
    "                    if sentiments_score > 0.5:\n",
    "                        good_count += 1\n",
    "                    elif sentiments_score <= 0.5:\n",
    "                        bad_count += 1\n",
    "                    total_score += sentiments_score\n",
    "\n",
    "            avg_score = total_score/len(s.sentences)\n",
    "            avg_score_list.append(avg_score)\n",
    "            good_count_list.append(good_count)\n",
    "            bad_count_list.append(bad_count)\n",
    "\n",
    "        # 將評分結果新增至原df並建新的CSV(路徑請視自身環境更動)\n",
    "        df2[\"正評數\"] = good_count_list\n",
    "        df2[\"負評數\"] = bad_count_list\n",
    "        df2[\"情感平均分數\"] = avg_score_list\n",
    "        df2.to_csv(f\"C:\\\\Users\\\\user\\\\Desktop\\\\ifoodie2\\\\{company}\\\\{restaurant}2.csv\",index=0,encoding='utf-8-sig',header=['來源網站','集團','品牌','標題','連結','菜系','評分','留言數','文章內容','食記資訊',\"正評數\",\"負評數\",\"情感平均分數\"])\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "### 為各個集團創建資料夾存放新的CSV檔(路徑請視自身環境更動)\n",
    "restaurant_list = [{\"company\":\"王品集團\",\"restaurant\": [\"王品牛排\",\"西堤\",\"陶板屋\",\"原燒\",\"聚北海道鍋物\",\"藝奇\",\"夏慕尼\",\"品田牧場\",\"石二鍋\",\"hot 7\",\"莆田\",\"青花驕\",\"享鴨\",\"丰禾\",\"樂越\",\"12MINI\",\"THE WANG\",\"和牛涮\",\"尬鍋\",\"肉次方\"]},\n",
    "                   {\"company\":\"瓦城泰統\",\"restaurant\": ['瓦城','非常泰','1010湘','大心','時時香','月月THAI','YABI KITCHEN']},\n",
    "                   {\"company\":\"漢來美食\",\"restaurant\": ['漢來海港','漢來名人坊','漢來蔬食','漢來軒','翠園粵菜','五梅先生','安那居','上菜','福園台菜','弁慶','精緻海鮮火鍋','糕餅小舖','大廳酒廊','漢來咖啡廳','Pavo','焰·鐵板燒']}]\n",
    "\n",
    "for n in range(3):\n",
    "  if not os.path.exists(f\"C:\\\\Users\\\\user\\\\Desktop\\\\ifoodie2\\\\{restaurant_list[n]['company']}\"):\n",
    "    os.mkdir(f\"C:\\\\Users\\\\user\\\\Desktop\\\\ifoodie2\\\\{restaurant_list[n]['company']}\")\n",
    "\n",
    "  for restaurant in range(len(restaurant_list[n][\"restaurant\"])):\n",
    "    Emotion_Analysis(restaurant_list[n][\"company\"],restaurant_list[n][\"restaurant\"][restaurant])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 對Tripadvisor.csv評論內容進行文本分析(情感) ####\n",
    "#### p.s : 因Tripadvisor文章較少,故不另限制文章發布日期\n",
    "import pandas as pd\n",
    "import json \n",
    "import time\n",
    "from snownlp import SnowNLP\n",
    "from snownlp import sentiment\n",
    "\n",
    "### 編寫文本分析函式\n",
    "def Emotion_Analysis(filename):\n",
    "    df = pd.read_csv(f'C:/Users/SCE/Desktop/{filename}.csv')   # 路徑請視自身環境更動\n",
    "    df2 = df.copy()\n",
    "    good_count_list= []\n",
    "    avg_score_list = []\n",
    "    bad_count_list= []\n",
    "\n",
    "    for row in range(df.shape[0]):\n",
    "        ## 列出每一列的評論內容,進行情感分析\n",
    "        review_content = str(df.iloc[row]['文章內容'])\n",
    "        total_score = 0\n",
    "        good_count = 0\n",
    "        bad_count = 0\n",
    "\n",
    "        s = SnowNLP(review_content)\n",
    "        for sentence in s.sentences : \n",
    "            if \"nan\" in sentence:\n",
    "                pass\n",
    "            else:\n",
    "                sentiments_score = SnowNLP(sentence).sentiments \n",
    "                total_score += sentiments_score\n",
    "                if sentiments_score > 0.5:\n",
    "                    good_count += 1\n",
    "                elif sentiments_score <= 0.5:\n",
    "                    bad_count += 1           \n",
    "                \n",
    "        avg_score = total_score/len(s.sentences)\n",
    "        avg_score_list.append(avg_score)\n",
    "        good_count_list.append(good_count)\n",
    "        bad_count_list.append(bad_count)\n",
    "\n",
    "    ## 將評分結果新增至原df並建新的CSV(路徑請視自身環境更動)\n",
    "    df2[\"正評數\"] = good_count_list\n",
    "    df2[\"負評數\"] = bad_count_list\n",
    "    df2[\"情感平均分數\"] = avg_score_list\n",
    "    df2.to_csv(f\"C:\\\\Users\\\\SCE\\\\Desktop\\\\{filename}2.csv\",index=0,encoding='utf-8-sig',header=['來源網站','集團','品牌','標題','店家地址','評論標題','發布時間','文章內容','評分',\"Lat\",\"Lon\",\"正評數\",\"負評數\",\"情感平均分數\"])\n",
    "\n",
    "### 執行\n",
    "Emotion_Analysis(\"Tripadvisor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 對google_map.csv評論內容進行文本分析(情感) ####\n",
    "import pandas as pd\n",
    "import json \n",
    "import time\n",
    "from snownlp import SnowNLP\n",
    "from snownlp import sentiment\n",
    "\n",
    "### 編寫文本分析函式\n",
    "def Emotion_Analysis(filename):\n",
    "    df = pd.read_csv(f'C:/Users/SCE/Desktop/{filename}.csv')   # 路徑請視自身環境更動\n",
    "    df2 = df.copy()\n",
    "    good_count_list= []\n",
    "    avg_score_list = []\n",
    "    bad_count_list= []\n",
    "\n",
    "    for row in range(df.shape[0]):\n",
    "        try:\n",
    "            # 列出每一列的評論內容及時間\n",
    "            review_content = str(df.iloc[row]['文章內容'])\n",
    "            article_time = df.iloc[row]['發布時間']\n",
    "            article_timestamp = int(time.mktime(time.strptime(article_time,\"%Y/%m/%d\")))\n",
    "            Stopby_timestamp = int(time.mktime(time.strptime(\"2021/4/1\",\"%Y/%m/%d\")))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        ## 進行情感分析\n",
    "        total_score = 0\n",
    "        good_count = 0\n",
    "        bad_count = 0\n",
    "        \n",
    "        # 只對一年內的文章進行分析\n",
    "        if article_timestamp > Stopby_timestamp :\n",
    "            s = SnowNLP(review_content)\n",
    "            for sentence in s.sentences : \n",
    "                if \"nan\" in sentence:\n",
    "                    pass\n",
    "                else:\n",
    "                    sentiments_score = SnowNLP(sentence).sentiments \n",
    "                    total_score += sentiments_score\n",
    "                    if sentiments_score > 0.5:\n",
    "                        good_count += 1\n",
    "                    elif sentiments_score <= 0.5:\n",
    "                        bad_count += 1           \n",
    "                \n",
    "        avg_score = total_score/len(s.sentences)\n",
    "        avg_score_list.append(avg_score)\n",
    "        good_count_list.append(good_count)\n",
    "        bad_count_list.append(bad_count)\n",
    "\n",
    "    ## 將評分結果新增至原df並建新的CSV(路徑請視自身環境更動)\n",
    "    df2[\"正評數\"] = good_count_list\n",
    "    df2[\"負評數\"] = bad_count_list\n",
    "    df2[\"情感平均分數\"] = avg_score_list\n",
    "    df2.to_csv(f\"C:\\\\Users\\\\SCE\\\\Desktop\\\\{filename}2.csv\",index=0,encoding='utf-8-sig',header=['來源網站','集團','品牌','標題','地址','發布時間','文章內容','評分',\"正評數\",\"負評數\",\"情感平均分數\"])\n",
    "\n",
    "### 執行\n",
    "Emotion_Analysis(\"google_map\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 對痞客邦.csv評論內容進行文本分析(情感) ####\n",
    "import pandas as pd\n",
    "import json \n",
    "import time\n",
    "from snownlp import SnowNLP\n",
    "from snownlp import sentiment\n",
    "\n",
    "### 編寫文本分析函式\n",
    "def Emotion_Analysis(filename):\n",
    "    df = pd.read_csv(f'C:/Users/SCE/Desktop/{filename}.csv')   # 路徑請視自身環境更動\n",
    "    df2 = df.copy()\n",
    "    good_count_list= []\n",
    "    avg_score_list = []\n",
    "    bad_count_list= []\n",
    "\n",
    "    for row in range(df.shape[0]):\n",
    "        try:\n",
    "            # 列出每一列的評論內容及時間\n",
    "            review_content = str(df.iloc[row]['文章內容'])\n",
    "            article_time = df.iloc[row]['發布時間']\n",
    "            article_timestamp = int(time.mktime(time.strptime(article_time,\"%Y/%m/%d\")))\n",
    "            Stopby_timestamp = int(time.mktime(time.strptime(\"2021/4/1\",\"%Y/%m/%d\")))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        ## 進行情感分析\n",
    "        total_score = 0\n",
    "        good_count = 0\n",
    "        bad_count = 0\n",
    "\n",
    "        # 只對一年內的文章進行分析\n",
    "        if article_timestamp > Stopby_timestamp :\n",
    "            s = SnowNLP(review_content)\n",
    "            for sentence in s.sentences : \n",
    "                if \"nan\" in sentence:\n",
    "                    pass\n",
    "                else:\n",
    "                    sentiments_score = SnowNLP(sentence).sentiments \n",
    "                    total_score += sentiments_score\n",
    "                    if sentiments_score > 0.5:\n",
    "                        good_count += 1\n",
    "                    elif sentiments_score <= 0.5:\n",
    "                        bad_count += 1           \n",
    "                \n",
    "        avg_score = total_score/len(s.sentences)\n",
    "        avg_score_list.append(avg_score)\n",
    "        good_count_list.append(good_count)\n",
    "        bad_count_list.append(bad_count)\n",
    "\n",
    "    ## 將評分結果新增至原df並建新的CSV(路徑請視自身環境更動)\n",
    "    df2[\"正評數\"] = good_count_list\n",
    "    df2[\"負評數\"] = bad_count_list\n",
    "    df2[\"情感平均分數\"] = avg_score_list\n",
    "    df2.to_csv(f\"C:\\\\Users\\\\SCE\\\\Desktop\\\\{filename}2.csv\",index=0,encoding='utf-8-sig',header=['來源網站','集團','品牌','發布時間','標題','文章內容',\"瀏覽數\",\"留言數\",\"正評數\",\"負評數\",\"情感平均分數\"])\n",
    "\n",
    "### 執行\n",
    "Emotion_Analysis(\"PIXNET\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38b44fdb8fc41f9fc70f1da60c5ee00afd5f7b7449fb412bc73745c85ccccbc3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
